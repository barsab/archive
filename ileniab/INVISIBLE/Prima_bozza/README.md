# 1. Mancanza del contatto fisico

![foto](https://github.com/ileniab/archive/blob/master/ileniab/INVISIBLE/Prima_bozza/Balella-tatto.png)

In questo periodo di distanziamento sociale il contatto fisico è diventato ormai un ricordo. 

Vorrei rendere visibile la presenza dell’altro utilizzando il senso del tatto, per permettere all'utente distogliersi dallo schermo e ritagliarsi un momento più intimo e personale. 

La mia attenzione si concentra sulla tattilità, la quale non è visibile o condivisibile, se si è distanti. Sarebbe quindi interessante riuscire ad avvicinare le persone lontane dando fisicità ai gesti e alle emozioni.

Come rendere però presente e tangibile una persona lontana? 

Si potrebbe pensare ad una coppia di oggetti che si attivano simultaneamente in base a come sono sfiorati e manipolati, anche le parole potrebbero influenzare l’esperienza. 

In base a ciò che si prova questo oggetto risponderebbe ad una serie di input determinati da suo utilizzatore da remoto. Questo strumento dovrà veicolare le emozioni e le sensazioni tattili tramite la superficie, il calore, la vibrazione, il colore e la luce.


### Reference
[_Phisicality - Monogrid_](http://mono-grid.com/en/project/physicality/)

![foto](https://www.innovation-nation.it/wp-content/uploads/2019/02/hand_4.jpeg)

L’installazione registra i dati degli oggetti che si toccano e li riproduce tramite vibrazioni e variazione di temperatura. Associano la sensazione tattile con una proiezione grafica.

# 2. Emozioni velate

![foto](https://github.com/ileniab/archive/blob/master/ileniab/INVISIBLE/Prima_bozza/Balella-volto.png)

Anche il viso coperto dalle mascherine vela in parte l’emotività di un’espressione. Ciò comporta un limite nel provare empatia.

Come è possibile rendere visibile la nostra espressione in un altro modo, quando siamo avvolti da guanti e celati dietro mascherine?

Si indagheranno i limiti del riconoscimento facciale, affidandosi soltanto all’espressività degli occhi. 

Tenendo conto dell’informazione limitata, si addestrerà l'algoritmo a riconosce le emozioni associando ad esse delle **parole**, o delle **immagini** (associate all'emozione in questione e selezionate magari dall'utente stesso a priori, per rendere più personale e diretta l'informazione prodotta dall'algoritmo) o delle **visualizzazioni grafiche**  che riusciranno a comunicare e a tradurre lo sguardo. 

Sarebbe interessante anche scoprire se c’è una interpretazione diversa a seconda dell’etnia o dello stato di provenienza.


### Reference

[_FaceApi_](https://learn.ml5js.org/docs/#/reference/face-api)

![reference__header-faceapi.png](http://rebeccazhou.hosting.nyu.edu/wp-content/uploads/2019/11/reference__header-faceapi.png)
